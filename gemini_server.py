import os
import asyncio
from dotenv import load_dotenv
from google import genai
import io
from PIL import Image as PILImage
from mcp.server.fastmcp import FastMCP, Image
from traceloop.sdk import Traceloop
from traceloop.sdk.decorators import workflow, task

# Load environment variables
load_dotenv()

# Initialize Traceloop for Instana Observability
# This will auto-instrument the application and send traces to Instana
# if TRACELOOP_BASE_URL and TRACELOOP_HEADERS are set.
Traceloop.init(app_name="gemini-mcp-server")

# Configure Gemini
API_KEY = os.getenv("GOOGLE_API_KEY")
if not API_KEY:
    raise ValueError("GOOGLE_API_KEY environment variable is required")

client = genai.Client(api_key=API_KEY)
from google.genai import types

# Use the specific model requested (gemini-2.5-flash-image)
MODEL_NAME = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-image")

# Create MCP Server
mcp = FastMCP("Gemini Service")

@mcp.tool()
@task(name="generate_image", version=1)
async def generate_image(prompt: str) -> Image:
    """
    Generates an image based on the prompt using Google's Gemini Nano Banana (gemini-2.5-flash-image).
    Use this tool whenever the user asks to draw, create, or generate an image, picture, or diagram.
    """
    try:
        response = await client.aio.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_modalities=["IMAGE", "TEXT"],
            )
        )
        
        # Parse response for inline image data
        if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if part.inline_data and part.inline_data.data:
                    # Compress image to avoid 1MB MCP limit
                    img_data = part.inline_data.data
                    with PILImage.open(io.BytesIO(img_data)) as img:
                        # Convert to RGB (in case of RGBA) for JPEG
                        if img.mode in ('RGBA', 'P'):
                            img = img.convert('RGB')
                        
                        # Resize if too large (max 1024x1024)
                        max_size = (1024, 1024)
                        img.thumbnail(max_size, PILImage.LANCZOS)
                        
                        output_buffer = io.BytesIO()
                        # Save as JPEG with 80% quality
                        img.save(output_buffer, format="JPEG", quality=80, optimize=True)
                        compressed_data = output_buffer.getvalue()
                        
                        return Image(data=compressed_data, format="jpeg")
        
        return Image(data=b"", format="jpeg")
    except Exception as e:
        raise RuntimeError(f"Error generating image: {str(e)}")

@mcp.tool()
@task(name="ask_gemini")
async def ask_gemini(prompt: str) -> str:
    """
    Asks Gemini a question or gives it a prompt to generate text.
    Use this for general queries, creative writing, or coding.
    DO NOT use this tool for generating images. Use 'generate_image' instead.
    """
    try:
        response = await client.aio.models.generate_content(
            model=MODEL_NAME,
            contents=prompt
        )
        if response.text:
            return response.text
        return "No text response generated by Gemini."
    except Exception as e:
        return f"Error communicating with Gemini: {str(e)}"

@workflow(name="gemini_mcp_workflow")
def start_server() -> None:
    """Start MCP server in streamable-http transport.
    
    This function blocks â€” call it from __main__.
    """
    mcp.run(transport="streamable-http")

if __name__ == "__main__":
    try:
        start_server()
    except KeyboardInterrupt:
        import sys
        sys.exit(0)
    except (BrokenPipeError, OSError):
        import sys
        sys.exit(0)
    except Exception as e:
        import sys
        print(f"Fatal error: {e}", file=sys.stderr)
        sys.exit(1)
